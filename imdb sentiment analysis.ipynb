{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3RIJtiF8P/teSdo/Pi6dc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princetondalmet/sentiment_analysis_imdb/blob/main/imdb%20sentiment%20analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w_F1iyQ1BK1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from numpy import array\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n"
      ],
      "metadata": {
        "id": "kSQM8r7F1qh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset but only keep the top n words and zero out the rest i.e keep vocabulary size as 5000\n",
        "top_words = 5000 #vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "metadata": {
        "id": "qqubN45-1-g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Inspect a sample review and its label.Note that the review is stored as a sequence of integers. These are word IDs that \n",
        "have been pre-assigned to individual words, and the label is an integer (0 for negative, 1 for positive).'''\n",
        "print('---review---')\n",
        "print(X_train[6])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHnjM-Pg2C-1",
        "outputId": "fad7e657-b5a5-4200-b2a4-a047d5327fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---review---\n",
            "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''We can use the dictionary returned by imdb.get_word_index() to map the review back to the original words.'''\n",
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[6]])\n",
        "print('---label---')\n",
        "print(y_train[6])\n",
        "\n",
        "print(word2id)\n",
        "\n",
        "print(id2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPD7JYYU2FHV",
        "outputId": "4ed96e65-6a6a-4156-cbb1-946fe6733827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximum review length and minimum review length.\n",
        "print('Maximum review length: {}'.format(\n",
        "len(max((X_train + X_test), key=len))))\n",
        "\n",
        "print('Minimum review length: {}'.format(\n",
        "len(min((X_train + X_test), key=len))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhHRmIeI2Iyy",
        "outputId": "c64d7b17-246e-46c0-f1c1-e2f03e55f71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 2697\n",
            "Minimum review length: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''In order to feed this data into our RNN, all input documents must have the same length. We will limit the maximum review length to maximum words by truncating \n",
        "longer reviews and padding shorter reviews with a null value (0). We can accomplish this task using the pad_sequences() function in Keras. Here, setting max_review_length \n",
        "to 500.'''\n",
        "\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n"
      ],
      "metadata": {
        "id": "IRzw6Zys2Nmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Remember that our input is a sequence of words (technically, integer word IDs) of maximum length = max_review_length, and our output is a binary sentiment \n",
        "label (0 or 1).\n",
        "'''\n",
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "MFC3Tf8Z2P-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''We first need to compile our model by specifying the loss function and optimizer we want to use while training, as well as any evaluation metrics \n",
        "we’d like to measure. Specify the appropriate parameters, including at least one metric ‘accuracy’.'''\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bja1IYjC2SkY",
        "outputId": "3065c07f-3bf5-4c4b-9b15-47421dc7ec1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 500, 32)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 260s 659ms/step - loss: 0.4942 - accuracy: 0.7502 - val_loss: 0.3815 - val_accuracy: 0.8232\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 256s 655ms/step - loss: 0.2968 - accuracy: 0.8797 - val_loss: 0.3086 - val_accuracy: 0.8728\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 252s 645ms/step - loss: 0.2654 - accuracy: 0.8955 - val_loss: 0.3802 - val_accuracy: 0.8326\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 251s 643ms/step - loss: 0.2343 - accuracy: 0.9101 - val_loss: 0.3118 - val_accuracy: 0.8753\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 254s 651ms/step - loss: 0.2292 - accuracy: 0.9128 - val_loss: 0.3210 - val_accuracy: 0.8725\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c5e5cab50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate Accuracy\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vroabPTv2alB",
        "outputId": "48e8772b-87e3-451e-d58e-ff5d91e4c680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 87.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run these codes first in order to install the necessary libraries and perform authorization\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zafQlVLD2cfC",
        "outputId": "c7f0f91e-9437-4272-a674-cb973548e9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 155514 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=None&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "https://accounts.google.com/o/oauth2/auth?client_id=None\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=None&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Error: End_of_file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount your Google Drive:\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EleSUCBl2fFD",
        "outputId": "6fcdadfc-d92d-4aad-af90-6fa4dd54397b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=None&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Error: Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=None&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After success run Drive FUSE program, you can create a directory Sentiment_Analysis and access your drive at /content/drive with using command\n",
        "import os\n",
        "os.mkdir(\"D:\\Python resume project\\Sentiment analysis\")\n",
        "os.chdir(\"/content/drive/\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB2ktwJX2hCS",
        "outputId": "40c8ed0b-e687-401c-eefe-bc97a52d8ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment_Analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Append your path\n",
        "import sys\n",
        "sys.path.append('/content/drive/Sentiment_Analysis')"
      ],
      "metadata": {
        "id": "qn0lhPkR2i4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now save the model in required directory\n",
        "model.save('/content/drive/Sentiment_Analysis/sentiment_analysis_model_new.h5')\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Kzp1Kz2kaI",
        "outputId": "de616d44-4d27-4ac3-d228-8a212c20ea70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the content of the directory\n",
        "os.chdir(\"/content/drive/Sentiment_Analysis\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9w2oLdh2mG5",
        "outputId": "3c041951-b758-4667-a427-f9d1f792fc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'D:\\Python resume project\\Sentiment analysis'   sentiment_analysis_model_new.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to load the saved model\n",
        "model = load_model('/content/drive/Sentiment_Analysis/sentiment_analysis_model_new.h5')\n",
        "print(\"Model Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tISmLW_T2nuJ",
        "outputId": "7cb96cc5-0aa9-4b6c-9af0-23b784e7b0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ]
    }
  ]
}